{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data API\n",
    "Tensorflow's Data API was designed to ingest and preprocess large datasets. \n",
    "\n",
    "Data API can **read** text files, binary files with fixed-size records, binary files with TFRecord format for records of varying sizes, supports reading from SQL databases, and other data sources like GCP's BigQuery.\n",
    "\n",
    "Data API can preprocess data like normalization, encodes text/categorical variables (using one-hot encoding, bag-of-words, or embeddings), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _dataset_ object is a sequence of data items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method _tf.data.Dataset.from_tensor_slices(X)_ splits input _X_ along the first dimension to generate data items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splices 1D input into scalar items\n",
    "dataset = tf.data.Dataset.from_tensor_slices([0,1,2,3,4])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splices 2D input into 1D items\n",
    "dataset = tf.data.Dataset.from_tensor_slices([[1,1],[2,2],[3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([3 3], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splices 3D input into 2D items\n",
    "dataset = tf.data.Dataset.from_tensor_slices([[[1,1],[1,1]],[[2,2],[2,2]],[[3,3],[3,3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1]\n",
      " [1 1]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 2]\n",
      " [2 2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [3 3]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic transformations\n",
    "### Repeat\n",
    "The function _repeat(n)_ repeats the data items in the dataset object, _n_ times. If _n=None_, the items are repeated infinitely. Interestingly, the repeats are not stored in memory. The number of times to repeat are recalled when an iterator is called to go through the items in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([0,1,2])\n",
    "dataset = dataset.repeat(2)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch\n",
    "The function _batch(n)_ will group the data items into batches of size _n_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.batch(3)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# You can drop a batch that isn't full fixed size\n",
    "dataset = tf.data.Dataset.from_tensor_slices([0,1,2,3,4])\n",
    "dataset = dataset.batch(2)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([0,1,2,3,4])\n",
    "dataset = dataset.batch(2, drop_remainder=True)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining transformations\n",
    "Transformation methods can be chained sequentially for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2], shape=(3,), dtype=int64)\n",
      "tf.Tensor([0 1 2], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(3).repeat(2).batch(3)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
